{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import subprocess\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "from scipy import stats\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.initializers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "5     3   78  50  32   88  31.0  0.248  26  1\n",
       "6    10  115   0   0    0  35.3  0.134  29  0\n",
       "7     2  197  70  45  543  30.5  0.158  53  1\n",
       "8     8  125  96   0    0   0.0  0.232  54  1\n",
       "9     4  110  92   0    0  37.6  0.191  30  0\n",
       "10   10  168  74   0    0  38.0  0.537  34  1\n",
       "11   10  139  80   0    0  27.1  1.441  57  0\n",
       "12    1  189  60  23  846  30.1  0.398  59  1\n",
       "13    5  166  72  19  175  25.8  0.587  51  1\n",
       "14    7  100   0   0    0  30.0  0.484  32  1\n",
       "15    0  118  84  47  230  45.8  0.551  31  1\n",
       "16    7  107  74   0    0  29.6  0.254  31  1\n",
       "17    1  103  30  38   83  43.3  0.183  33  0\n",
       "18    1  115  70  30   96  34.6  0.529  32  1\n",
       "19    3  126  88  41  235  39.3  0.704  27  0\n",
       "20    8   99  84   0    0  35.4  0.388  50  0\n",
       "21    7  196  90   0    0  39.8  0.451  41  1\n",
       "22    9  119  80  35    0  29.0  0.263  29  1\n",
       "23   11  143  94  33  146  36.6  0.254  51  1\n",
       "24   10  125  70  26  115  31.1  0.205  41  1\n",
       "25    7  147  76   0    0  39.4  0.257  43  1\n",
       "26    1   97  66  15  140  23.2  0.487  22  0\n",
       "27   13  145  82  19  110  22.2  0.245  57  0\n",
       "28    5  117  92   0    0  34.1  0.337  38  0\n",
       "29    5  109  75  26    0  36.0  0.546  60  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "737   2   99  60  17  160  36.6  0.453  21  0\n",
       "738   1  102  74   0    0  39.5  0.293  42  1\n",
       "739  11  120  80  37  150  42.3  0.785  48  1\n",
       "740   3  102  44  20   94  30.8  0.400  26  0\n",
       "741   1  109  58  18  116  28.5  0.219  22  0\n",
       "742   9  140  94   0    0  32.7  0.734  45  1\n",
       "743  13  153  88  37  140  40.6  1.174  39  0\n",
       "744  12  100  84  33  105  30.0  0.488  46  0\n",
       "745   1  147  94  41    0  49.3  0.358  27  1\n",
       "746   1   81  74  41   57  46.3  1.096  32  0\n",
       "747   3  187  70  22  200  36.4  0.408  36  1\n",
       "748   6  162  62   0    0  24.3  0.178  50  1\n",
       "749   4  136  70   0    0  31.2  1.182  22  1\n",
       "750   1  121  78  39   74  39.0  0.261  28  0\n",
       "751   3  108  62  24    0  26.0  0.223  25  0\n",
       "752   0  181  88  44  510  43.3  0.222  26  1\n",
       "753   8  154  78  32    0  32.4  0.443  45  1\n",
       "754   1  128  88  39  110  36.5  1.057  37  1\n",
       "755   7  137  90  41    0  32.0  0.391  39  0\n",
       "756   0  123  72   0    0  36.3  0.258  52  1\n",
       "757   1  106  76   0    0  37.5  0.197  26  0\n",
       "758   6  190  92   0    0  35.5  0.278  66  1\n",
       "759   2   88  58  26   16  28.4  0.766  22  0\n",
       "760   9  170  74  31    0  44.0  0.403  43  1\n",
       "761   9   89  62   0    0  22.5  0.142  33  0\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"F:/ML/Zenrays/AI_ML_Feb25_Kormangla/hands on/pima-indians-diabetes.csv\")\n",
    "df.columns = np.arange(9) #rename labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8]\n",
    "Y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "funct = []\n",
    "funct.append('tanh')\n",
    "funct.append('sigmoid')\n",
    "funct.append('relu')\n",
    "funct.append('softplus')\n",
    "funct.append('softsign')\n",
    "funct.append('hard_sigmoid')\n",
    "funct.append('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input layer activation</th>\n",
       "      <th>Hidden layer activation</th>\n",
       "      <th>Output layer activation</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Input layer activation, Hidden layer activation, Output layer activation, accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysisdf = pd.DataFrame(columns= [\"Input layer activation\",\"Hidden layer activation\", \"Output layer activation\",\n",
    "                                    \"accuracy\"])\n",
    "l = 0\n",
    "analysisdf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "767/767 [==============================] - 0s 391us/step - loss: 5.0094 - acc: 0.1695\n",
      "Epoch 2/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 3.4552 - acc: 0.4237\n",
      "Epoch 3/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 3.4137 - acc: 0.3950\n",
      "Epoch 4/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 3.3084 - acc: 0.4407\n",
      "Epoch 5/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 3.2391 - acc: 0.5554\n",
      "Epoch 6/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 3.2532 - acc: 0.5267\n",
      "Epoch 7/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 3.2152 - acc: 0.4824\n",
      "Epoch 8/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 3.1888 - acc: 0.6258\n",
      "Epoch 9/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 3.2111 - acc: 0.5932\n",
      "Epoch 10/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 3.1935 - acc: 0.5984\n",
      "Epoch 11/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 3.2193 - acc: 0.5867\n",
      "Epoch 12/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 3.2033 - acc: 0.5606\n",
      "Epoch 13/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 3.2029 - acc: 0.5267\n",
      "Epoch 14/500\n",
      "767/767 [==============================] - 0s 16us/step - loss: 3.2054 - acc: 0.5280\n",
      "Epoch 15/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 3.1802 - acc: 0.6336\n",
      "Epoch 16/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 3.2062 - acc: 0.5958\n",
      "Epoch 17/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 3.1492 - acc: 0.6571\n",
      "Epoch 18/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 2.9406 - acc: 0.6741\n",
      "Epoch 19/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.7949 - acc: 0.6284\n",
      "Epoch 20/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6119 - acc: 0.6506\n",
      "Epoch 21/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6092 - acc: 0.6806\n",
      "Epoch 22/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6241 - acc: 0.6767\n",
      "Epoch 23/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.6079 - acc: 0.6949\n",
      "Epoch 24/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6032 - acc: 0.6884\n",
      "Epoch 25/500\n",
      "767/767 [==============================] - 0s 30us/step - loss: 0.5975 - acc: 0.6884\n",
      "Epoch 26/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5897 - acc: 0.6962\n",
      "Epoch 27/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5976 - acc: 0.7001\n",
      "Epoch 28/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5794 - acc: 0.7171\n",
      "Epoch 29/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5761 - acc: 0.6858\n",
      "Epoch 30/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5645 - acc: 0.7093\n",
      "Epoch 31/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5822 - acc: 0.7027\n",
      "Epoch 32/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5684 - acc: 0.7158\n",
      "Epoch 33/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5623 - acc: 0.7223\n",
      "Epoch 34/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5967 - acc: 0.6897\n",
      "Epoch 35/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6185 - acc: 0.7171\n",
      "Epoch 36/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6009 - acc: 0.7093\n",
      "Epoch 37/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5689 - acc: 0.7132\n",
      "Epoch 38/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.6247 - acc: 0.7158\n",
      "Epoch 39/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5695 - acc: 0.7119\n",
      "Epoch 40/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5588 - acc: 0.7327\n",
      "Epoch 41/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6250 - acc: 0.7053\n",
      "Epoch 42/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5815 - acc: 0.7106\n",
      "Epoch 43/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5622 - acc: 0.7236\n",
      "Epoch 44/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6311 - acc: 0.7236\n",
      "Epoch 45/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5621 - acc: 0.7080\n",
      "Epoch 46/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5864 - acc: 0.6897\n",
      "Epoch 47/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5566 - acc: 0.7262\n",
      "Epoch 48/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5604 - acc: 0.7405\n",
      "Epoch 49/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5530 - acc: 0.7184\n",
      "Epoch 50/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5395 - acc: 0.7510\n",
      "Epoch 51/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5384 - acc: 0.7419\n",
      "Epoch 52/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5377 - acc: 0.7366\n",
      "Epoch 53/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5689 - acc: 0.7327\n",
      "Epoch 54/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5453 - acc: 0.7301\n",
      "Epoch 55/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5621 - acc: 0.7158\n",
      "Epoch 56/500\n",
      "767/767 [==============================] - ETA: 0s - loss: 0.5495 - acc: 0.740 - 0s 20us/step - loss: 0.5280 - acc: 0.7432\n",
      "Epoch 57/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5555 - acc: 0.7327\n",
      "Epoch 58/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5444 - acc: 0.7353\n",
      "Epoch 59/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5543 - acc: 0.7419\n",
      "Epoch 60/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5703 - acc: 0.7093\n",
      "Epoch 61/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5284 - acc: 0.7379\n",
      "Epoch 62/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5558 - acc: 0.7419\n",
      "Epoch 63/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5628 - acc: 0.7419\n",
      "Epoch 64/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5390 - acc: 0.7301\n",
      "Epoch 65/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5625 - acc: 0.7197\n",
      "Epoch 66/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5308 - acc: 0.7484\n",
      "Epoch 67/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5981 - acc: 0.6636\n",
      "Epoch 68/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5515 - acc: 0.7314\n",
      "Epoch 69/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5349 - acc: 0.7419\n",
      "Epoch 70/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5463 - acc: 0.7536\n",
      "Epoch 71/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5448 - acc: 0.7419\n",
      "Epoch 72/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5977 - acc: 0.7223\n",
      "Epoch 73/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5440 - acc: 0.7601\n",
      "Epoch 74/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5596 - acc: 0.7314\n",
      "Epoch 75/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5368 - acc: 0.7379\n",
      "Epoch 76/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6463 - acc: 0.6910\n",
      "Epoch 77/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5671 - acc: 0.7249\n",
      "Epoch 78/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5511 - acc: 0.7353\n",
      "Epoch 79/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5345 - acc: 0.7523\n",
      "Epoch 80/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5304 - acc: 0.7275\n",
      "Epoch 81/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5349 - acc: 0.7445\n",
      "Epoch 82/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6117 - acc: 0.7379\n",
      "Epoch 83/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5502 - acc: 0.7236\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 20us/step - loss: 0.5320 - acc: 0.7484\n",
      "Epoch 85/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5314 - acc: 0.7379\n",
      "Epoch 86/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5696 - acc: 0.7210\n",
      "Epoch 87/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5551 - acc: 0.7484\n",
      "Epoch 88/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5247 - acc: 0.7523\n",
      "Epoch 89/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6126 - acc: 0.7093\n",
      "Epoch 90/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5370 - acc: 0.7340\n",
      "Epoch 91/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5459 - acc: 0.7419\n",
      "Epoch 92/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5552 - acc: 0.7288\n",
      "Epoch 93/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5421 - acc: 0.7458\n",
      "Epoch 94/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6518 - acc: 0.7392\n",
      "Epoch 95/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5701 - acc: 0.7510\n",
      "Epoch 96/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6542 - acc: 0.6780\n",
      "Epoch 97/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5651 - acc: 0.7106\n",
      "Epoch 98/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5300 - acc: 0.7510\n",
      "Epoch 99/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5216 - acc: 0.7497\n",
      "Epoch 100/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5259 - acc: 0.7497\n",
      "Epoch 101/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5301 - acc: 0.7432\n",
      "Epoch 102/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5325 - acc: 0.7445\n",
      "Epoch 103/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5707 - acc: 0.7549\n",
      "Epoch 104/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5308 - acc: 0.7405\n",
      "Epoch 105/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5356 - acc: 0.7471\n",
      "Epoch 106/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5771 - acc: 0.7392\n",
      "Epoch 107/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5308 - acc: 0.7588\n",
      "Epoch 108/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5699 - acc: 0.6949\n",
      "Epoch 109/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5229 - acc: 0.7458\n",
      "Epoch 110/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5360 - acc: 0.7445\n",
      "Epoch 111/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6785 - acc: 0.7119\n",
      "Epoch 112/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5729 - acc: 0.7027\n",
      "Epoch 113/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5372 - acc: 0.7366\n",
      "Epoch 114/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5300 - acc: 0.7471\n",
      "Epoch 115/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5268 - acc: 0.7484\n",
      "Epoch 116/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5523 - acc: 0.7484\n",
      "Epoch 117/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5719 - acc: 0.7484\n",
      "Epoch 118/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5352 - acc: 0.7405\n",
      "Epoch 119/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5589 - acc: 0.7445\n",
      "Epoch 120/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5281 - acc: 0.7445\n",
      "Epoch 121/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5479 - acc: 0.7340\n",
      "Epoch 122/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5797 - acc: 0.7027\n",
      "Epoch 123/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5511 - acc: 0.7236\n",
      "Epoch 124/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5267 - acc: 0.7392\n",
      "Epoch 125/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5221 - acc: 0.7484\n",
      "Epoch 126/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5689 - acc: 0.7471\n",
      "Epoch 127/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.6025 - acc: 0.7184\n",
      "Epoch 128/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5637 - acc: 0.7158\n",
      "Epoch 129/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5177 - acc: 0.7523\n",
      "Epoch 130/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5179 - acc: 0.7458\n",
      "Epoch 131/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5241 - acc: 0.7275\n",
      "Epoch 132/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5578 - acc: 0.7301\n",
      "Epoch 133/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5549 - acc: 0.7301\n",
      "Epoch 134/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5234 - acc: 0.7497\n",
      "Epoch 135/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6490 - acc: 0.7275\n",
      "Epoch 136/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5587 - acc: 0.7093\n",
      "Epoch 137/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5076 - acc: 0.7562\n",
      "Epoch 138/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5433 - acc: 0.7549\n",
      "Epoch 139/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5062 - acc: 0.7601\n",
      "Epoch 140/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5812 - acc: 0.7353\n",
      "Epoch 141/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5246 - acc: 0.7588\n",
      "Epoch 142/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5759 - acc: 0.6923\n",
      "Epoch 143/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5868 - acc: 0.6754\n",
      "Epoch 144/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5501 - acc: 0.7197\n",
      "Epoch 145/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5384 - acc: 0.7392\n",
      "Epoch 146/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5324 - acc: 0.7458\n",
      "Epoch 147/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5589 - acc: 0.7640\n",
      "Epoch 148/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5203 - acc: 0.7653\n",
      "Epoch 149/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5587 - acc: 0.7353\n",
      "Epoch 150/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5315 - acc: 0.7432\n",
      "Epoch 151/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5314 - acc: 0.7392\n",
      "Epoch 152/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5350 - acc: 0.7458\n",
      "Epoch 153/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5556 - acc: 0.7001\n",
      "Epoch 154/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5236 - acc: 0.7471\n",
      "Epoch 155/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5342 - acc: 0.7392\n",
      "Epoch 156/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5771 - acc: 0.7132\n",
      "Epoch 157/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6021 - acc: 0.7275\n",
      "Epoch 158/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5343 - acc: 0.7497\n",
      "Epoch 159/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5484 - acc: 0.7353\n",
      "Epoch 160/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5321 - acc: 0.7471\n",
      "Epoch 161/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5326 - acc: 0.7666\n",
      "Epoch 162/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5400 - acc: 0.7471\n",
      "Epoch 163/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5918 - acc: 0.6793\n",
      "Epoch 164/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5119 - acc: 0.7679\n",
      "Epoch 165/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5309 - acc: 0.7536\n",
      "Epoch 166/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5362 - acc: 0.7510\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 22us/step - loss: 0.5118 - acc: 0.7588\n",
      "Epoch 168/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5575 - acc: 0.7458\n",
      "Epoch 169/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5572 - acc: 0.7184\n",
      "Epoch 170/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5144 - acc: 0.7510\n",
      "Epoch 171/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5664 - acc: 0.7627\n",
      "Epoch 172/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.7772 - acc: 0.6662\n",
      "Epoch 173/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5216 - acc: 0.7458\n",
      "Epoch 174/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5301 - acc: 0.7497\n",
      "Epoch 175/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5198 - acc: 0.7614\n",
      "Epoch 176/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5577 - acc: 0.7262\n",
      "Epoch 177/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5595 - acc: 0.7432\n",
      "Epoch 178/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5128 - acc: 0.7405\n",
      "Epoch 179/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6252 - acc: 0.7784\n",
      "Epoch 180/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5879 - acc: 0.6780\n",
      "Epoch 181/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5285 - acc: 0.7275\n",
      "Epoch 182/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5127 - acc: 0.7419\n",
      "Epoch 183/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4997 - acc: 0.7679\n",
      "Epoch 184/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5296 - acc: 0.7601\n",
      "Epoch 185/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5267 - acc: 0.7314\n",
      "Epoch 186/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4969 - acc: 0.7601\n",
      "Epoch 187/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6562 - acc: 0.7275\n",
      "Epoch 188/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5255 - acc: 0.7432\n",
      "Epoch 189/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4992 - acc: 0.7575\n",
      "Epoch 190/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.7094 - acc: 0.6610\n",
      "Epoch 191/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5442 - acc: 0.7405\n",
      "Epoch 192/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5116 - acc: 0.7640\n",
      "Epoch 193/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5688 - acc: 0.7171\n",
      "Epoch 194/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5496 - acc: 0.7314\n",
      "Epoch 195/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5219 - acc: 0.7419\n",
      "Epoch 196/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5100 - acc: 0.7562\n",
      "Epoch 197/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5057 - acc: 0.7458\n",
      "Epoch 198/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5234 - acc: 0.7275\n",
      "Epoch 199/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5143 - acc: 0.7549\n",
      "Epoch 200/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4910 - acc: 0.7679\n",
      "Epoch 201/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.9614 - acc: 0.6728\n",
      "Epoch 202/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5165 - acc: 0.7510\n",
      "Epoch 203/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5071 - acc: 0.7523\n",
      "Epoch 204/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5179 - acc: 0.7458\n",
      "Epoch 205/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5153 - acc: 0.7510\n",
      "Epoch 206/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6028 - acc: 0.7419\n",
      "Epoch 207/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5859 - acc: 0.7093\n",
      "Epoch 208/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4977 - acc: 0.7562\n",
      "Epoch 209/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5250 - acc: 0.7471\n",
      "Epoch 210/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5299 - acc: 0.7575\n",
      "Epoch 211/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5531 - acc: 0.7445\n",
      "Epoch 212/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5953 - acc: 0.7262\n",
      "Epoch 213/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5038 - acc: 0.7497\n",
      "Epoch 214/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5331 - acc: 0.7523\n",
      "Epoch 215/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5400 - acc: 0.7275\n",
      "Epoch 216/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5149 - acc: 0.7366\n",
      "Epoch 217/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5088 - acc: 0.7419\n",
      "Epoch 218/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5409 - acc: 0.7627\n",
      "Epoch 219/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6079 - acc: 0.6767\n",
      "Epoch 220/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5144 - acc: 0.7562\n",
      "Epoch 221/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5025 - acc: 0.7562\n",
      "Epoch 222/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5010 - acc: 0.7627\n",
      "Epoch 223/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5301 - acc: 0.7510\n",
      "Epoch 224/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5187 - acc: 0.7419\n",
      "Epoch 225/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5522 - acc: 0.7366\n",
      "Epoch 226/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5095 - acc: 0.7536\n",
      "Epoch 227/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5100 - acc: 0.7640\n",
      "Epoch 228/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5725 - acc: 0.7419\n",
      "Epoch 229/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5402 - acc: 0.7379\n",
      "Epoch 230/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5136 - acc: 0.7275\n",
      "Epoch 231/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5150 - acc: 0.7510\n",
      "Epoch 232/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5171 - acc: 0.7549\n",
      "Epoch 233/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5144 - acc: 0.7379\n",
      "Epoch 234/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5274 - acc: 0.7549\n",
      "Epoch 235/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5476 - acc: 0.7432\n",
      "Epoch 236/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5374 - acc: 0.7223\n",
      "Epoch 237/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5887 - acc: 0.6884\n",
      "Epoch 238/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5229 - acc: 0.7575\n",
      "Epoch 239/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5044 - acc: 0.7614\n",
      "Epoch 240/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4974 - acc: 0.7744\n",
      "Epoch 241/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5081 - acc: 0.7549\n",
      "Epoch 242/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5072 - acc: 0.7549\n",
      "Epoch 243/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5245 - acc: 0.7484\n",
      "Epoch 244/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5345 - acc: 0.7392\n",
      "Epoch 245/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5213 - acc: 0.7471\n",
      "Epoch 246/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5398 - acc: 0.7575\n",
      "Epoch 247/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6112 - acc: 0.6506\n",
      "Epoch 248/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5292 - acc: 0.7145\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 20us/step - loss: 0.4961 - acc: 0.7601\n",
      "Epoch 250/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5231 - acc: 0.7679\n",
      "Epoch 251/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5363 - acc: 0.7484\n",
      "Epoch 252/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4928 - acc: 0.7731\n",
      "Epoch 253/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5012 - acc: 0.7510\n",
      "Epoch 254/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6467 - acc: 0.6741\n",
      "Epoch 255/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5424 - acc: 0.7223\n",
      "Epoch 256/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5162 - acc: 0.7497\n",
      "Epoch 257/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5062 - acc: 0.7718\n",
      "Epoch 258/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5178 - acc: 0.7627\n",
      "Epoch 259/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5381 - acc: 0.7379\n",
      "Epoch 260/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4999 - acc: 0.7562\n",
      "Epoch 261/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4870 - acc: 0.7692\n",
      "Epoch 262/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5515 - acc: 0.7562\n",
      "Epoch 263/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5061 - acc: 0.7445\n",
      "Epoch 264/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5686 - acc: 0.7145\n",
      "Epoch 265/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5095 - acc: 0.7549\n",
      "Epoch 266/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5618 - acc: 0.7549\n",
      "Epoch 267/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5232 - acc: 0.7718\n",
      "Epoch 268/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5605 - acc: 0.7523\n",
      "Epoch 269/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5064 - acc: 0.7445\n",
      "Epoch 270/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5325 - acc: 0.7249\n",
      "Epoch 271/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4944 - acc: 0.7601\n",
      "Epoch 272/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4976 - acc: 0.7471\n",
      "Epoch 273/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6413 - acc: 0.7197\n",
      "Epoch 274/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5209 - acc: 0.7340\n",
      "Epoch 275/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4952 - acc: 0.7562\n",
      "Epoch 276/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4811 - acc: 0.7692\n",
      "Epoch 277/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6775 - acc: 0.7249\n",
      "Epoch 278/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5085 - acc: 0.7640\n",
      "Epoch 279/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5617 - acc: 0.7575\n",
      "Epoch 280/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6043 - acc: 0.7223\n",
      "Epoch 281/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5020 - acc: 0.7523\n",
      "Epoch 282/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5137 - acc: 0.7640\n",
      "Epoch 283/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6434 - acc: 0.7432\n",
      "Epoch 284/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4948 - acc: 0.7562\n",
      "Epoch 285/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5096 - acc: 0.7523\n",
      "Epoch 286/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4886 - acc: 0.7640\n",
      "Epoch 287/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5303 - acc: 0.7510\n",
      "Epoch 288/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5109 - acc: 0.7340\n",
      "Epoch 289/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5067 - acc: 0.7484\n",
      "Epoch 290/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5102 - acc: 0.7497\n",
      "Epoch 291/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5265 - acc: 0.7366\n",
      "Epoch 292/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5216 - acc: 0.7419\n",
      "Epoch 293/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4951 - acc: 0.7562\n",
      "Epoch 294/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5473 - acc: 0.7353\n",
      "Epoch 295/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.4943 - acc: 0.7614\n",
      "Epoch 296/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5148 - acc: 0.7445\n",
      "Epoch 297/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5229 - acc: 0.7314\n",
      "Epoch 298/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5011 - acc: 0.7549\n",
      "Epoch 299/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5124 - acc: 0.7392\n",
      "Epoch 300/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5352 - acc: 0.7366\n",
      "Epoch 301/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5044 - acc: 0.7471\n",
      "Epoch 302/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5185 - acc: 0.7640\n",
      "Epoch 303/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5117 - acc: 0.7640\n",
      "Epoch 304/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4949 - acc: 0.7614\n",
      "Epoch 305/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5374 - acc: 0.7392\n",
      "Epoch 306/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5178 - acc: 0.7484\n",
      "Epoch 307/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4997 - acc: 0.7627\n",
      "Epoch 308/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4944 - acc: 0.7484\n",
      "Epoch 309/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5184 - acc: 0.7432\n",
      "Epoch 310/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5134 - acc: 0.7653\n",
      "Epoch 311/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5368 - acc: 0.7275\n",
      "Epoch 312/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4913 - acc: 0.7614\n",
      "Epoch 313/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5771 - acc: 0.7080\n",
      "Epoch 314/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4925 - acc: 0.7484\n",
      "Epoch 315/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4810 - acc: 0.7562\n",
      "Epoch 316/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5435 - acc: 0.7353\n",
      "Epoch 317/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4927 - acc: 0.7653\n",
      "Epoch 318/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4798 - acc: 0.7744\n",
      "Epoch 319/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5245 - acc: 0.7432\n",
      "Epoch 320/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5236 - acc: 0.7484\n",
      "Epoch 321/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5342 - acc: 0.7497\n",
      "Epoch 322/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5059 - acc: 0.7575\n",
      "Epoch 323/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6570 - acc: 0.7392\n",
      "Epoch 324/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.8425 - acc: 0.6714\n",
      "Epoch 325/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.6596 - acc: 0.5958\n",
      "Epoch 326/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6532 - acc: 0.6037\n",
      "Epoch 327/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6437 - acc: 0.6154\n",
      "Epoch 328/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6300 - acc: 0.6402\n",
      "Epoch 329/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6114 - acc: 0.6545\n",
      "Epoch 330/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5880 - acc: 0.6819\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 18us/step - loss: 0.5629 - acc: 0.6975\n",
      "Epoch 332/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5440 - acc: 0.7066\n",
      "Epoch 333/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5318 - acc: 0.7210\n",
      "Epoch 334/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5238 - acc: 0.7223\n",
      "Epoch 335/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5180 - acc: 0.7223\n",
      "Epoch 336/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5085 - acc: 0.7340\n",
      "Epoch 337/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4986 - acc: 0.7536\n",
      "Epoch 338/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5003 - acc: 0.7575\n",
      "Epoch 339/500\n",
      "767/767 [==============================] - 0s 29us/step - loss: 0.4962 - acc: 0.7588\n",
      "Epoch 340/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5010 - acc: 0.7510\n",
      "Epoch 341/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.4876 - acc: 0.7666\n",
      "Epoch 342/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4819 - acc: 0.7601\n",
      "Epoch 343/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5286 - acc: 0.7601\n",
      "Epoch 344/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4771 - acc: 0.7784\n",
      "Epoch 345/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6061 - acc: 0.7627\n",
      "Epoch 346/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5255 - acc: 0.7366\n",
      "Epoch 347/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4858 - acc: 0.7549\n",
      "Epoch 348/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4710 - acc: 0.7705\n",
      "Epoch 349/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5544 - acc: 0.7419\n",
      "Epoch 350/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.4832 - acc: 0.7640\n",
      "Epoch 351/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4951 - acc: 0.7366\n",
      "Epoch 352/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5572 - acc: 0.7392\n",
      "Epoch 353/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5461 - acc: 0.7275\n",
      "Epoch 354/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5087 - acc: 0.7288\n",
      "Epoch 355/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5053 - acc: 0.7601\n",
      "Epoch 356/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5080 - acc: 0.7614\n",
      "Epoch 357/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5408 - acc: 0.7366\n",
      "Epoch 358/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4873 - acc: 0.7497\n",
      "Epoch 359/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4957 - acc: 0.7640\n",
      "Epoch 360/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4920 - acc: 0.7536\n",
      "Epoch 361/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5122 - acc: 0.7301\n",
      "Epoch 362/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5269 - acc: 0.7405\n",
      "Epoch 363/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5614 - acc: 0.7119\n",
      "Epoch 364/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4928 - acc: 0.7575\n",
      "Epoch 365/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4846 - acc: 0.7679\n",
      "Epoch 366/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.7629 - acc: 0.7184\n",
      "Epoch 367/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5049 - acc: 0.7627\n",
      "Epoch 368/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.4939 - acc: 0.7731\n",
      "Epoch 369/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5746 - acc: 0.7080\n",
      "Epoch 370/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4794 - acc: 0.7601\n",
      "Epoch 371/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5018 - acc: 0.7419\n",
      "Epoch 372/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5393 - acc: 0.7510\n",
      "Epoch 373/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4966 - acc: 0.7523\n",
      "Epoch 374/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5568 - acc: 0.7484\n",
      "Epoch 375/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5045 - acc: 0.7562\n",
      "Epoch 376/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5049 - acc: 0.7705\n",
      "Epoch 377/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4948 - acc: 0.7484\n",
      "Epoch 378/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5194 - acc: 0.7497\n",
      "Epoch 379/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6198 - acc: 0.7040\n",
      "Epoch 380/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5183 - acc: 0.7392\n",
      "Epoch 381/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4863 - acc: 0.7640\n",
      "Epoch 382/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5117 - acc: 0.7445\n",
      "Epoch 383/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4788 - acc: 0.7640\n",
      "Epoch 384/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4824 - acc: 0.7588\n",
      "Epoch 385/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.4855 - acc: 0.7614\n",
      "Epoch 386/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4978 - acc: 0.7562\n",
      "Epoch 387/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5254 - acc: 0.7392\n",
      "Epoch 388/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4886 - acc: 0.7601\n",
      "Epoch 389/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4780 - acc: 0.7692\n",
      "Epoch 390/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5303 - acc: 0.7445\n",
      "Epoch 391/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4990 - acc: 0.7458\n",
      "Epoch 392/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4826 - acc: 0.7744\n",
      "Epoch 393/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5124 - acc: 0.7523\n",
      "Epoch 394/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4835 - acc: 0.7731\n",
      "Epoch 395/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4953 - acc: 0.7497\n",
      "Epoch 396/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5531 - acc: 0.7523\n",
      "Epoch 397/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4932 - acc: 0.7471\n",
      "Epoch 398/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4867 - acc: 0.7588\n",
      "Epoch 399/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5694 - acc: 0.7353\n",
      "Epoch 400/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5007 - acc: 0.7497\n",
      "Epoch 401/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5554 - acc: 0.7419\n",
      "Epoch 402/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4815 - acc: 0.7666\n",
      "Epoch 403/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5017 - acc: 0.7484\n",
      "Epoch 404/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4922 - acc: 0.7575\n",
      "Epoch 405/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4876 - acc: 0.7523\n",
      "Epoch 406/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5632 - acc: 0.6832\n",
      "Epoch 407/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4820 - acc: 0.7705\n",
      "Epoch 408/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4849 - acc: 0.7601\n",
      "Epoch 409/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4806 - acc: 0.7679\n",
      "Epoch 410/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6272 - acc: 0.7340\n",
      "Epoch 411/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4760 - acc: 0.7679\n",
      "Epoch 412/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5658 - acc: 0.7314\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 18us/step - loss: 0.5294 - acc: 0.7379\n",
      "Epoch 414/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5034 - acc: 0.7614\n",
      "Epoch 415/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5008 - acc: 0.7484\n",
      "Epoch 416/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.4940 - acc: 0.7562\n",
      "Epoch 417/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4849 - acc: 0.7523\n",
      "Epoch 418/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5118 - acc: 0.7471\n",
      "Epoch 419/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5455 - acc: 0.7210\n",
      "Epoch 420/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4839 - acc: 0.7471\n",
      "Epoch 421/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5286 - acc: 0.7575\n",
      "Epoch 422/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5164 - acc: 0.7405\n",
      "Epoch 423/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5640 - acc: 0.7484\n",
      "Epoch 424/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4860 - acc: 0.7692\n",
      "Epoch 425/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5186 - acc: 0.7510\n",
      "Epoch 426/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5314 - acc: 0.7471\n",
      "Epoch 427/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5707 - acc: 0.7679\n",
      "Epoch 428/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5241 - acc: 0.7458\n",
      "Epoch 429/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4849 - acc: 0.7627\n",
      "Epoch 430/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5503 - acc: 0.7432\n",
      "Epoch 431/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5414 - acc: 0.7458\n",
      "Epoch 432/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5174 - acc: 0.7366\n",
      "Epoch 433/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4885 - acc: 0.7497\n",
      "Epoch 434/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4834 - acc: 0.7601\n",
      "Epoch 435/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4841 - acc: 0.7614\n",
      "Epoch 436/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5202 - acc: 0.7471\n",
      "Epoch 437/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5022 - acc: 0.7392\n",
      "Epoch 438/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5319 - acc: 0.7705\n",
      "Epoch 439/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4815 - acc: 0.7575\n",
      "Epoch 440/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6068 - acc: 0.6441\n",
      "Epoch 441/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5234 - acc: 0.7419\n",
      "Epoch 442/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5444 - acc: 0.7549\n",
      "Epoch 443/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4906 - acc: 0.7601\n",
      "Epoch 444/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4925 - acc: 0.7614\n",
      "Epoch 445/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5320 - acc: 0.7588\n",
      "Epoch 446/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4830 - acc: 0.7692\n",
      "Epoch 447/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4975 - acc: 0.7640\n",
      "Epoch 448/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5125 - acc: 0.7497\n",
      "Epoch 449/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4836 - acc: 0.7705\n",
      "Epoch 450/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4878 - acc: 0.7588\n",
      "Epoch 451/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5027 - acc: 0.7497\n",
      "Epoch 452/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5782 - acc: 0.7145\n",
      "Epoch 453/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.4804 - acc: 0.7666\n",
      "Epoch 454/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4976 - acc: 0.7653\n",
      "Epoch 455/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4910 - acc: 0.7692\n",
      "Epoch 456/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5796 - acc: 0.7080\n",
      "Epoch 457/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5232 - acc: 0.7340\n",
      "Epoch 458/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5481 - acc: 0.7301\n",
      "Epoch 459/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5595 - acc: 0.7040\n",
      "Epoch 460/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5185 - acc: 0.7353\n",
      "Epoch 461/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4987 - acc: 0.7419\n",
      "Epoch 462/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5028 - acc: 0.7340\n",
      "Epoch 463/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4892 - acc: 0.7432\n",
      "Epoch 464/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4977 - acc: 0.7405\n",
      "Epoch 465/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4679 - acc: 0.7718\n",
      "Epoch 466/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6872 - acc: 0.6167\n",
      "Epoch 467/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6100 - acc: 0.6519\n",
      "Epoch 468/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5583 - acc: 0.7040\n",
      "Epoch 469/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5296 - acc: 0.7392\n",
      "Epoch 470/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5004 - acc: 0.7614\n",
      "Epoch 471/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4838 - acc: 0.7614\n",
      "Epoch 472/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.4830 - acc: 0.7731\n",
      "Epoch 473/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4845 - acc: 0.7614\n",
      "Epoch 474/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4852 - acc: 0.7549\n",
      "Epoch 475/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.4861 - acc: 0.7510\n",
      "Epoch 476/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.4839 - acc: 0.7523\n",
      "Epoch 477/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4791 - acc: 0.7562\n",
      "Epoch 478/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4908 - acc: 0.7562\n",
      "Epoch 479/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5477 - acc: 0.7405\n",
      "Epoch 480/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4924 - acc: 0.7549\n",
      "Epoch 481/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5168 - acc: 0.7497\n",
      "Epoch 482/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5521 - acc: 0.6871\n",
      "Epoch 483/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5077 - acc: 0.7562\n",
      "Epoch 484/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4955 - acc: 0.7627\n",
      "Epoch 485/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.4802 - acc: 0.7653\n",
      "Epoch 486/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.4730 - acc: 0.7810\n",
      "Epoch 487/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5108 - acc: 0.7314\n",
      "Epoch 488/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5100 - acc: 0.7575\n",
      "Epoch 489/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5001 - acc: 0.7405\n",
      "Epoch 490/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5786 - acc: 0.7471\n",
      "Epoch 491/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4820 - acc: 0.7640\n",
      "Epoch 492/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5102 - acc: 0.7405\n",
      "Epoch 493/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.4784 - acc: 0.7640\n",
      "Epoch 494/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5088 - acc: 0.7653\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 23us/step - loss: 0.5203 - acc: 0.7575\n",
      "Epoch 496/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5622 - acc: 0.7184\n",
      "Epoch 497/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5015 - acc: 0.7666\n",
      "Epoch 498/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5319 - acc: 0.7471\n",
      "Epoch 499/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.4870 - acc: 0.7627\n",
      "Epoch 500/500\n",
      "767/767 [==============================] - 0s 26us/step - loss: 0.4912 - acc: 0.7458\n",
      "767/767 [==============================] - 0s 81us/step\n",
      "Epoch 1/500\n",
      "767/767 [==============================] - 0s 545us/step - loss: 0.6516 - acc: 0.6480\n",
      "Epoch 2/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6425 - acc: 0.6506\n",
      "Epoch 3/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6384 - acc: 0.6545\n",
      "Epoch 4/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6336 - acc: 0.6519\n",
      "Epoch 5/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6292 - acc: 0.6519\n",
      "Epoch 6/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6250 - acc: 0.6532\n",
      "Epoch 7/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6217 - acc: 0.6519\n",
      "Epoch 8/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6181 - acc: 0.6519\n",
      "Epoch 9/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6143 - acc: 0.6519\n",
      "Epoch 10/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6141 - acc: 0.6519\n",
      "Epoch 11/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.6103 - acc: 0.6532\n",
      "Epoch 12/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6081 - acc: 0.6519\n",
      "Epoch 13/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6053 - acc: 0.6519\n",
      "Epoch 14/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6041 - acc: 0.6532\n",
      "Epoch 15/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.6016 - acc: 0.6532\n",
      "Epoch 16/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.6016 - acc: 0.6532\n",
      "Epoch 17/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.6006 - acc: 0.6532\n",
      "Epoch 18/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5980 - acc: 0.6558\n",
      "Epoch 19/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5963 - acc: 0.6519\n",
      "Epoch 20/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5939 - acc: 0.6545\n",
      "Epoch 21/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5957 - acc: 0.6545\n",
      "Epoch 22/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5900 - acc: 0.6545\n",
      "Epoch 23/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5924 - acc: 0.6571\n",
      "Epoch 24/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5886 - acc: 0.6597\n",
      "Epoch 25/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5912 - acc: 0.6597\n",
      "Epoch 26/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5897 - acc: 0.6649\n",
      "Epoch 27/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5859 - acc: 0.6649\n",
      "Epoch 28/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5849 - acc: 0.6688\n",
      "Epoch 29/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5825 - acc: 0.6662\n",
      "Epoch 30/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5839 - acc: 0.6767\n",
      "Epoch 31/500\n",
      "767/767 [==============================] - 0s 23us/step - loss: 0.5847 - acc: 0.6754\n",
      "Epoch 32/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5810 - acc: 0.6767\n",
      "Epoch 33/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5863 - acc: 0.6714\n",
      "Epoch 34/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5780 - acc: 0.6780\n",
      "Epoch 35/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5734 - acc: 0.6871\n",
      "Epoch 36/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5773 - acc: 0.6767\n",
      "Epoch 37/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5772 - acc: 0.6871\n",
      "Epoch 38/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5754 - acc: 0.6962\n",
      "Epoch 39/500\n",
      "767/767 [==============================] - 0s 18us/step - loss: 0.5727 - acc: 0.6871\n",
      "Epoch 40/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5769 - acc: 0.6884\n",
      "Epoch 41/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5722 - acc: 0.7093\n",
      "Epoch 42/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5717 - acc: 0.6988\n",
      "Epoch 43/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5695 - acc: 0.6975\n",
      "Epoch 44/500\n",
      "767/767 [==============================] - 0s 27us/step - loss: 0.5745 - acc: 0.7197\n",
      "Epoch 45/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5728 - acc: 0.7001\n",
      "Epoch 46/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5722 - acc: 0.7106\n",
      "Epoch 47/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5651 - acc: 0.7106\n",
      "Epoch 48/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5662 - acc: 0.7171\n",
      "Epoch 49/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5637 - acc: 0.7158\n",
      "Epoch 50/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5633 - acc: 0.7171\n",
      "Epoch 51/500\n",
      "767/767 [==============================] - 0s 21us/step - loss: 0.5606 - acc: 0.7145\n",
      "Epoch 52/500\n",
      "767/767 [==============================] - 0s 25us/step - loss: 0.5643 - acc: 0.7106\n",
      "Epoch 53/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5629 - acc: 0.7197\n",
      "Epoch 54/500\n",
      "767/767 [==============================] - 0s 20us/step - loss: 0.5633 - acc: 0.7236\n",
      "Epoch 55/500\n",
      "767/767 [==============================] - 0s 22us/step - loss: 0.5622 - acc: 0.7210\n",
      "Epoch 56/500\n",
      "767/767 [==============================] - 0s 17us/step - loss: 0.5639 - acc: 0.7236\n",
      "Epoch 57/500\n",
      "767/767 [==============================] - 0s 16us/step - loss: 0.5626 - acc: 0.7236\n",
      "Epoch 58/500\n",
      "767/767 [==============================] - 0s 16us/step - loss: 0.5599 - acc: 0.7223\n",
      "Epoch 59/500\n",
      "767/767 [==============================] - 0s 16us/step - loss: 0.5603 - acc: 0.7171\n",
      "Epoch 60/500\n",
      "100/767 [==>...........................] - ETA: 0s - loss: 0.5498 - acc: 0.7200"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f32d9bd627b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfuncti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RMSProp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#validation_split=0.33\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0manalysisdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Input layer activation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1202\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fun in funct:\n",
    "    for func in funct:\n",
    "        for functi in funct:\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Dense(8, input_dim=8, activation=fun, kernel_initializer='RandomUniform', bias_initializer='zeros'))\n",
    "            model.add(Dense(4, activation= func))\n",
    "            model.add(Dense(1, activation= functi))\n",
    "            model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=['accuracy'])\n",
    "            history = model.fit(X, Y, epochs=500, batch_size=100, ) #validation_split=0.33\n",
    "            scores = model.evaluate(X, Y)\n",
    "            analysisdf.loc[l,\"Input layer activation\"]=  fun\n",
    "            analysisdf.loc[l,\"Hidden layer activation\"]= func\n",
    "            analysisdf.loc[l,\"Output layer activation\"]= functi\n",
    "            analysisdf.loc[l,\"accuracy\"]= (\" \\n%s: %.2f%%\" % ( model.metrics_names[1], scores[1]*100))\n",
    "            l += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analysisdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-82cb6a041715>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalysisdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'analysisdf' is not defined"
     ]
    }
   ],
   "source": [
    "analysisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.plot(history.history['acc'])\n",
    "    #plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x77ffa566d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 139us/step\n",
      "\n",
      "acc: 79.79%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381520</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.461997</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526080</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.628141</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065756</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.552764</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560358</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566319</td>\n",
       "      <td>0.195986</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403875</td>\n",
       "      <td>0.581981</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.136635</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.206856</td>\n",
       "      <td>0.384501</td>\n",
       "      <td>0.217336</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447094</td>\n",
       "      <td>0.173356</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.271868</td>\n",
       "      <td>0.682563</td>\n",
       "      <td>0.201964</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.537688</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441133</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.517588</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.098109</td>\n",
       "      <td>0.645306</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.515648</td>\n",
       "      <td>0.192570</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.585693</td>\n",
       "      <td>0.267293</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527571</td>\n",
       "      <td>0.132365</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.984925</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593145</td>\n",
       "      <td>0.159266</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.597990</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.078992</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.172577</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.628141</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.135934</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.054227</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.738693</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587183</td>\n",
       "      <td>0.076430</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.165485</td>\n",
       "      <td>0.345753</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.728643</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.330849</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536513</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.189125</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.160120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588674</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.177305</td>\n",
       "      <td>0.630402</td>\n",
       "      <td>0.301879</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.137489</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0.424739</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487332</td>\n",
       "      <td>0.280102</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.165485</td>\n",
       "      <td>0.605067</td>\n",
       "      <td>0.467976</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.502513</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.447094</td>\n",
       "      <td>0.175064</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.738693</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.734724</td>\n",
       "      <td>0.119556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.407035</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.067376</td>\n",
       "      <td>0.690015</td>\n",
       "      <td>0.434671</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>0.542474</td>\n",
       "      <td>0.140905</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362146</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.683417</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464978</td>\n",
       "      <td>0.471392</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.608040</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.581222</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.542714</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387481</td>\n",
       "      <td>0.061913</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909548</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.645306</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.155850</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.643216</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>0.543964</td>\n",
       "      <td>0.418019</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.133646</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618090</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.532663</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558867</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.954774</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529061</td>\n",
       "      <td>0.085397</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.293766</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.854271</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.138770</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335320</td>\n",
       "      <td>0.027327</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.490313</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.613065</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548435</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.608040</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448584</td>\n",
       "      <td>0.115713</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.467337</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.058824  0.427136  0.540984  0.292929  0.000000  0.396423  0.116567   \n",
       "1    0.470588  0.919598  0.524590  0.000000  0.000000  0.347243  0.253629   \n",
       "2    0.058824  0.447236  0.540984  0.232323  0.111111  0.418778  0.038002   \n",
       "3    0.000000  0.688442  0.327869  0.353535  0.198582  0.642325  0.943638   \n",
       "4    0.294118  0.582915  0.606557  0.000000  0.000000  0.381520  0.052519   \n",
       "5    0.176471  0.391960  0.409836  0.323232  0.104019  0.461997  0.072588   \n",
       "6    0.588235  0.577889  0.000000  0.000000  0.000000  0.526080  0.023911   \n",
       "7    0.117647  0.989950  0.573770  0.454545  0.641844  0.454545  0.034159   \n",
       "8    0.470588  0.628141  0.786885  0.000000  0.000000  0.000000  0.065756   \n",
       "9    0.235294  0.552764  0.754098  0.000000  0.000000  0.560358  0.048249   \n",
       "10   0.588235  0.844221  0.606557  0.000000  0.000000  0.566319  0.195986   \n",
       "11   0.588235  0.698492  0.655738  0.000000  0.000000  0.403875  0.581981   \n",
       "12   0.058824  0.949749  0.491803  0.232323  1.000000  0.448584  0.136635   \n",
       "13   0.294118  0.834171  0.590164  0.191919  0.206856  0.384501  0.217336   \n",
       "14   0.411765  0.502513  0.000000  0.000000  0.000000  0.447094  0.173356   \n",
       "15   0.000000  0.592965  0.688525  0.474747  0.271868  0.682563  0.201964   \n",
       "16   0.411765  0.537688  0.606557  0.000000  0.000000  0.441133  0.075149   \n",
       "17   0.058824  0.517588  0.245902  0.383838  0.098109  0.645306  0.044833   \n",
       "18   0.058824  0.577889  0.573770  0.303030  0.113475  0.515648  0.192570   \n",
       "19   0.176471  0.633166  0.721311  0.414141  0.277778  0.585693  0.267293   \n",
       "20   0.470588  0.497487  0.688525  0.000000  0.000000  0.527571  0.132365   \n",
       "21   0.411765  0.984925  0.737705  0.000000  0.000000  0.593145  0.159266   \n",
       "22   0.529412  0.597990  0.655738  0.353535  0.000000  0.432191  0.078992   \n",
       "23   0.647059  0.718593  0.770492  0.333333  0.172577  0.545455  0.075149   \n",
       "24   0.588235  0.628141  0.573770  0.262626  0.135934  0.463487  0.054227   \n",
       "25   0.411765  0.738693  0.622951  0.000000  0.000000  0.587183  0.076430   \n",
       "26   0.058824  0.487437  0.540984  0.151515  0.165485  0.345753  0.174637   \n",
       "27   0.764706  0.728643  0.672131  0.191919  0.130024  0.330849  0.071307   \n",
       "28   0.294118  0.587940  0.754098  0.000000  0.000000  0.508197  0.110589   \n",
       "29   0.294118  0.547739  0.614754  0.262626  0.000000  0.536513  0.199829   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "737  0.117647  0.497487  0.491803  0.171717  0.189125  0.545455  0.160120   \n",
       "738  0.058824  0.512563  0.606557  0.000000  0.000000  0.588674  0.091802   \n",
       "739  0.647059  0.603015  0.655738  0.373737  0.177305  0.630402  0.301879   \n",
       "740  0.176471  0.512563  0.360656  0.202020  0.111111  0.459016  0.137489   \n",
       "741  0.058824  0.547739  0.475410  0.181818  0.137116  0.424739  0.060205   \n",
       "742  0.529412  0.703518  0.770492  0.000000  0.000000  0.487332  0.280102   \n",
       "743  0.764706  0.768844  0.721311  0.373737  0.165485  0.605067  0.467976   \n",
       "744  0.705882  0.502513  0.688525  0.333333  0.124113  0.447094  0.175064   \n",
       "745  0.058824  0.738693  0.770492  0.414141  0.000000  0.734724  0.119556   \n",
       "746  0.058824  0.407035  0.606557  0.414141  0.067376  0.690015  0.434671   \n",
       "747  0.176471  0.939698  0.573770  0.222222  0.236407  0.542474  0.140905   \n",
       "748  0.352941  0.814070  0.508197  0.000000  0.000000  0.362146  0.042699   \n",
       "749  0.235294  0.683417  0.573770  0.000000  0.000000  0.464978  0.471392   \n",
       "750  0.058824  0.608040  0.639344  0.393939  0.087470  0.581222  0.078138   \n",
       "751  0.176471  0.542714  0.508197  0.242424  0.000000  0.387481  0.061913   \n",
       "752  0.000000  0.909548  0.721311  0.444444  0.602837  0.645306  0.061486   \n",
       "753  0.470588  0.773869  0.639344  0.323232  0.000000  0.482861  0.155850   \n",
       "754  0.058824  0.643216  0.721311  0.393939  0.130024  0.543964  0.418019   \n",
       "755  0.411765  0.688442  0.737705  0.414141  0.000000  0.476900  0.133646   \n",
       "756  0.000000  0.618090  0.590164  0.000000  0.000000  0.540984  0.076857   \n",
       "757  0.058824  0.532663  0.622951  0.000000  0.000000  0.558867  0.050811   \n",
       "758  0.352941  0.954774  0.754098  0.000000  0.000000  0.529061  0.085397   \n",
       "759  0.117647  0.442211  0.475410  0.262626  0.018913  0.423249  0.293766   \n",
       "760  0.529412  0.854271  0.606557  0.313131  0.000000  0.655738  0.138770   \n",
       "761  0.529412  0.447236  0.508197  0.000000  0.000000  0.335320  0.027327   \n",
       "762  0.588235  0.507538  0.622951  0.484848  0.212766  0.490313  0.039710   \n",
       "763  0.117647  0.613065  0.573770  0.272727  0.000000  0.548435  0.111870   \n",
       "764  0.294118  0.608040  0.590164  0.232323  0.132388  0.390462  0.071307   \n",
       "765  0.058824  0.633166  0.491803  0.000000  0.000000  0.448584  0.115713   \n",
       "766  0.058824  0.467337  0.573770  0.313131  0.000000  0.453055  0.101196   \n",
       "\n",
       "            7    8  \n",
       "0    0.166667  0.0  \n",
       "1    0.183333  1.0  \n",
       "2    0.000000  0.0  \n",
       "3    0.200000  1.0  \n",
       "4    0.150000  0.0  \n",
       "5    0.083333  1.0  \n",
       "6    0.133333  0.0  \n",
       "7    0.533333  1.0  \n",
       "8    0.550000  1.0  \n",
       "9    0.150000  0.0  \n",
       "10   0.216667  1.0  \n",
       "11   0.600000  0.0  \n",
       "12   0.633333  1.0  \n",
       "13   0.500000  1.0  \n",
       "14   0.183333  1.0  \n",
       "15   0.166667  1.0  \n",
       "16   0.166667  1.0  \n",
       "17   0.200000  0.0  \n",
       "18   0.183333  1.0  \n",
       "19   0.100000  0.0  \n",
       "20   0.483333  0.0  \n",
       "21   0.333333  1.0  \n",
       "22   0.133333  1.0  \n",
       "23   0.500000  1.0  \n",
       "24   0.333333  1.0  \n",
       "25   0.366667  1.0  \n",
       "26   0.016667  0.0  \n",
       "27   0.600000  0.0  \n",
       "28   0.283333  0.0  \n",
       "29   0.650000  0.0  \n",
       "..        ...  ...  \n",
       "737  0.000000  0.0  \n",
       "738  0.350000  1.0  \n",
       "739  0.450000  1.0  \n",
       "740  0.083333  0.0  \n",
       "741  0.016667  0.0  \n",
       "742  0.400000  1.0  \n",
       "743  0.300000  0.0  \n",
       "744  0.416667  0.0  \n",
       "745  0.100000  1.0  \n",
       "746  0.183333  0.0  \n",
       "747  0.250000  1.0  \n",
       "748  0.483333  1.0  \n",
       "749  0.016667  1.0  \n",
       "750  0.116667  0.0  \n",
       "751  0.066667  0.0  \n",
       "752  0.083333  1.0  \n",
       "753  0.400000  1.0  \n",
       "754  0.266667  1.0  \n",
       "755  0.300000  0.0  \n",
       "756  0.516667  1.0  \n",
       "757  0.083333  0.0  \n",
       "758  0.750000  1.0  \n",
       "759  0.016667  0.0  \n",
       "760  0.366667  1.0  \n",
       "761  0.200000  0.0  \n",
       "762  0.700000  0.0  \n",
       "763  0.100000  0.0  \n",
       "764  0.150000  0.0  \n",
       "765  0.433333  1.0  \n",
       "766  0.033333  0.0  \n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing\n",
    "dfn = (df-df.min())/(df.max()-df.min())\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfn.iloc[:,0:8]\n",
    "Y = dfn.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=8, activation='relu', kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "767/767 [==============================] - 0s 359us/step - loss: 0.6883 - acc: 0.6519\n",
      "Epoch 2/150\n",
      "767/767 [==============================] - 0s 11us/step - loss: 0.6824 - acc: 0.6519\n",
      "Epoch 3/150\n",
      "767/767 [==============================] - 0s 6us/step - loss: 0.6792 - acc: 0.6519\n",
      "Epoch 4/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6764 - acc: 0.6519\n",
      "Epoch 5/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6744 - acc: 0.6519\n",
      "Epoch 6/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6725 - acc: 0.6519\n",
      "Epoch 7/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6705 - acc: 0.6519\n",
      "Epoch 8/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6688 - acc: 0.6519\n",
      "Epoch 9/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6672 - acc: 0.6519\n",
      "Epoch 10/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6660 - acc: 0.6519\n",
      "Epoch 11/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6647 - acc: 0.6519\n",
      "Epoch 12/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6634 - acc: 0.6519\n",
      "Epoch 13/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6623 - acc: 0.6519\n",
      "Epoch 14/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6612 - acc: 0.6519\n",
      "Epoch 15/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6601 - acc: 0.6519\n",
      "Epoch 16/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6591 - acc: 0.6519\n",
      "Epoch 17/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6581 - acc: 0.6519\n",
      "Epoch 18/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6571 - acc: 0.6519\n",
      "Epoch 19/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6561 - acc: 0.6519\n",
      "Epoch 20/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6551 - acc: 0.6519\n",
      "Epoch 21/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6541 - acc: 0.6519\n",
      "Epoch 22/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6532 - acc: 0.6519\n",
      "Epoch 23/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6524 - acc: 0.6519\n",
      "Epoch 24/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6514 - acc: 0.6519\n",
      "Epoch 25/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6504 - acc: 0.6519\n",
      "Epoch 26/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6495 - acc: 0.6519\n",
      "Epoch 27/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6486 - acc: 0.6519\n",
      "Epoch 28/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6476 - acc: 0.6519\n",
      "Epoch 29/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6467 - acc: 0.6519\n",
      "Epoch 30/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6458 - acc: 0.6519\n",
      "Epoch 31/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6449 - acc: 0.6519\n",
      "Epoch 32/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6440 - acc: 0.6519\n",
      "Epoch 33/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.6432 - acc: 0.6519\n",
      "Epoch 34/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6422 - acc: 0.6519\n",
      "Epoch 35/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6412 - acc: 0.6519\n",
      "Epoch 36/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6403 - acc: 0.6519\n",
      "Epoch 37/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6393 - acc: 0.6519\n",
      "Epoch 38/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6384 - acc: 0.6519\n",
      "Epoch 39/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6374 - acc: 0.6519\n",
      "Epoch 40/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6364 - acc: 0.6519\n",
      "Epoch 41/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6355 - acc: 0.6519\n",
      "Epoch 42/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6348 - acc: 0.6519\n",
      "Epoch 43/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6337 - acc: 0.6519\n",
      "Epoch 44/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6328 - acc: 0.6519\n",
      "Epoch 45/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6319 - acc: 0.6519\n",
      "Epoch 46/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6309 - acc: 0.6519\n",
      "Epoch 47/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6303 - acc: 0.6519\n",
      "Epoch 48/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6293 - acc: 0.6519\n",
      "Epoch 49/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6283 - acc: 0.6519\n",
      "Epoch 50/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6277 - acc: 0.6519\n",
      "Epoch 51/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6266 - acc: 0.6519\n",
      "Epoch 52/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6258 - acc: 0.6519\n",
      "Epoch 53/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6253 - acc: 0.6519\n",
      "Epoch 54/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6242 - acc: 0.6519\n",
      "Epoch 55/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6235 - acc: 0.6519\n",
      "Epoch 56/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6227 - acc: 0.6519\n",
      "Epoch 57/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.6218 - acc: 0.6519\n",
      "Epoch 58/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6211 - acc: 0.6519\n",
      "Epoch 59/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6202 - acc: 0.6519\n",
      "Epoch 60/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6194 - acc: 0.6519\n",
      "Epoch 61/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6186 - acc: 0.6519\n",
      "Epoch 62/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6178 - acc: 0.6519\n",
      "Epoch 63/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.6171 - acc: 0.6519\n",
      "Epoch 64/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6162 - acc: 0.6519\n",
      "Epoch 65/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6154 - acc: 0.6519\n",
      "Epoch 66/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6151 - acc: 0.6519\n",
      "Epoch 67/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6139 - acc: 0.6519\n",
      "Epoch 68/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6132 - acc: 0.6519\n",
      "Epoch 69/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6124 - acc: 0.6519\n",
      "Epoch 70/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6116 - acc: 0.6519\n",
      "Epoch 71/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.6108 - acc: 0.6519\n",
      "Epoch 72/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6103 - acc: 0.6519\n",
      "Epoch 73/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6093 - acc: 0.6519\n",
      "Epoch 74/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6085 - acc: 0.6519\n",
      "Epoch 75/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6079 - acc: 0.6519\n",
      "Epoch 76/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6071 - acc: 0.6519\n",
      "Epoch 77/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6063 - acc: 0.6519\n",
      "Epoch 78/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6056 - acc: 0.6519\n",
      "Epoch 79/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6048 - acc: 0.6519\n",
      "Epoch 80/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.6042 - acc: 0.6519\n",
      "Epoch 81/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6034 - acc: 0.6519\n",
      "Epoch 82/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6027 - acc: 0.6519\n",
      "Epoch 83/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6019 - acc: 0.6519\n",
      "Epoch 84/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6011 - acc: 0.6519\n",
      "Epoch 85/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.6003 - acc: 0.6519\n",
      "Epoch 86/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.5995 - acc: 0.6519\n",
      "Epoch 87/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5989 - acc: 0.6519\n",
      "Epoch 88/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5980 - acc: 0.6519\n",
      "Epoch 89/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.5973 - acc: 0.6519\n",
      "Epoch 90/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5965 - acc: 0.6519\n",
      "Epoch 91/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5957 - acc: 0.6519\n",
      "Epoch 92/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5948 - acc: 0.6519\n",
      "Epoch 93/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5942 - acc: 0.6519\n",
      "Epoch 94/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5935 - acc: 0.6519\n",
      "Epoch 95/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5926 - acc: 0.6519\n",
      "Epoch 96/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5919 - acc: 0.6519\n",
      "Epoch 97/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5913 - acc: 0.6519\n",
      "Epoch 98/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5905 - acc: 0.6519\n",
      "Epoch 99/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5901 - acc: 0.6519\n",
      "Epoch 100/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5893 - acc: 0.6519\n",
      "Epoch 101/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5887 - acc: 0.6519\n",
      "Epoch 102/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5880 - acc: 0.6519\n",
      "Epoch 103/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5874 - acc: 0.6519\n",
      "Epoch 104/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5871 - acc: 0.6519\n",
      "Epoch 105/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5864 - acc: 0.6519\n",
      "Epoch 106/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5857 - acc: 0.6519\n",
      "Epoch 107/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5854 - acc: 0.6519\n",
      "Epoch 108/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5846 - acc: 0.6519\n",
      "Epoch 109/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5841 - acc: 0.6519\n",
      "Epoch 110/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5839 - acc: 0.6519\n",
      "Epoch 111/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5831 - acc: 0.6519\n",
      "Epoch 112/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5825 - acc: 0.6519\n",
      "Epoch 113/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5820 - acc: 0.6519\n",
      "Epoch 114/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5813 - acc: 0.6519\n",
      "Epoch 115/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5807 - acc: 0.6519\n",
      "Epoch 116/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5803 - acc: 0.6519\n",
      "Epoch 117/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5797 - acc: 0.6519\n",
      "Epoch 118/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5801 - acc: 0.6519\n",
      "Epoch 119/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5786 - acc: 0.6519\n",
      "Epoch 120/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5782 - acc: 0.6519\n",
      "Epoch 121/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5779 - acc: 0.6519\n",
      "Epoch 122/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5772 - acc: 0.6519\n",
      "Epoch 123/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5771 - acc: 0.6519\n",
      "Epoch 124/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5763 - acc: 0.6519\n",
      "Epoch 125/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5757 - acc: 0.6519\n",
      "Epoch 126/150\n",
      "767/767 [==============================] - 0s 44us/step - loss: 0.5753 - acc: 0.6519\n",
      "Epoch 127/150\n",
      "767/767 [==============================] - 0s 10us/step - loss: 0.5747 - acc: 0.6519\n",
      "Epoch 128/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5743 - acc: 0.6519\n",
      "Epoch 129/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5741 - acc: 0.6519\n",
      "Epoch 130/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5736 - acc: 0.6519\n",
      "Epoch 131/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5727 - acc: 0.6519\n",
      "Epoch 132/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5722 - acc: 0.6519\n",
      "Epoch 133/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5719 - acc: 0.6519\n",
      "Epoch 134/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5716 - acc: 0.6519\n",
      "Epoch 135/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5709 - acc: 0.6519\n",
      "Epoch 136/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5703 - acc: 0.6519\n",
      "Epoch 137/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5698 - acc: 0.6519\n",
      "Epoch 138/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5693 - acc: 0.6519\n",
      "Epoch 139/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5688 - acc: 0.6519\n",
      "Epoch 140/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5685 - acc: 0.6519\n",
      "Epoch 141/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5681 - acc: 0.6519\n",
      "Epoch 142/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5673 - acc: 0.6519\n",
      "Epoch 143/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5668 - acc: 0.6519\n",
      "Epoch 144/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5663 - acc: 0.6519\n",
      "Epoch 145/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5662 - acc: 0.6519\n",
      "Epoch 146/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5654 - acc: 0.6519\n",
      "Epoch 147/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5648 - acc: 0.6519\n",
      "Epoch 148/150\n",
      "767/767 [==============================] - 0s 7us/step - loss: 0.5645 - acc: 0.6519\n",
      "Epoch 149/150\n",
      "767/767 [==============================] - 0s 9us/step - loss: 0.5639 - acc: 0.6519\n",
      "Epoch 150/150\n",
      "767/767 [==============================] - 0s 8us/step - loss: 0.5636 - acc: 0.6519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xdf17f8c630>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=150, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 110us/step\n",
      "\n",
      "acc: 65.19%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
